#!/usr/bin/env python3
"""
Pokroƒçil√Ω n√°stroj na humaniz√°ciu AI textu - transformuje text tak, aby pre≈°iel AI detektormi.
Pou≈æ√≠va viacero techn√≠k na vytvorenie prirodzene vyzeraj√∫ceho textu.
"""

import re
import random
import string
from typing import List, Dict, Tuple
import unicodedata

class AITextHumanizer:
    """Pokroƒçil√Ω humaniz√°tor AI textu s viacer√Ωmi technikami."""
    
    def __init__(self):
        """Inicializuje humaniz√°tor s datab√°zami synon√Ωm a transform√°ci√≠."""
        
        # Synonym√° pre ƒçast√∫ v√Ωrazu
        self.synonyms = {
            "v√Ωznamn√Ω": ["podstatn√Ω", "z√°sadn√Ω", "kƒæ√∫ƒçov√Ω", "d√¥le≈æit√Ω", "relevantn√Ω"],
            "d√¥le≈æit√Ω": ["v√Ωznamn√Ω", "kƒæ√∫ƒçov√Ω", "podstatn√Ω", "z√°va≈æn√Ω", "kritick√Ω"],
            "efekt√≠vny": ["√∫ƒçinn√Ω", "eficientn√Ω", "√∫spe≈°n√Ω", "funguj√∫ci", "produktivn√Ω"],
            "modern√Ω": ["s√∫ƒçasn√Ω", "aktu√°lny", "dne≈°n√Ω", "pokroƒçil√Ω", "najnov≈°√≠"],
            "komplexn√Ω": ["zlo≈æit√Ω", "komplikovan√Ω", "rozsiahly", "v≈°estrann√Ω", "mnohostrann√Ω"],
            "systematick√Ω": ["s√∫stavn√Ω", "metodick√Ω", "organizovan√Ω", "≈°trukt√∫rovan√Ω", "usporiadan√Ω"],
            "v√Ωznamn√Ω": ["podstatn√Ω", "z√°sadn√Ω", "d√¥le≈æit√Ω", "relevantn√Ω", "kƒæ√∫ƒçov√Ω"],
            "implement√°cia": ["zavedenie", "realiz√°cia", "uplat≈àovanie", "aplik√°cia", "vykonanie"],
            "anal√Ωza": ["rozbor", "sk√∫manie", "pos√∫denie", "≈°t√∫dium", "vyhodnotenie"],
            "optimaliz√°cia": ["zlep≈°ovanie", "zdokonaƒæovanie", "optimalizovanie", "zefekt√≠vnenie"],
            "technol√≥gia": ["technika", "technologick√© rie≈°enie", "technick√Ω pr√≠stup", "met√≥da"]
        }
        
        # Preformulovat vety
        self.sentence_starters = [
            "V kontexte tejto problematiky",
            "Z hƒæadiska praktickej aplik√°cie", 
            "Pri bli≈æ≈°om sk√∫man√≠ sa ukazuje, ≈æe",
            "D√¥kladn√° anal√Ωza odhaƒæuje",
            "V s√∫vislosti s touto t√©mou",
            "Na z√°klade dostupn√Ωch √∫dajov",
            "V√Ωskumn√© zistenia naznaƒçuj√∫",
            "V tejto s√∫vislosti je potrebn√© zd√¥razni≈•",
            "S ohƒæadom na uveden√© skutoƒçnosti"
        ]
        
        # Connecting phrases pre prirodzenos≈•
        self.connectors = [
            "navy≈°e", "okrem toho", "ƒèalej", "podobne", "z√°rove≈à",
            "napriek tomu", "jednako", "av≈°ak", "naopak", "s√∫ƒçasne",
            "v tejto s√∫vislosti", "v danom kontexte", "vzhƒæadom na to",
            "s ohƒæadom na", "ber√∫c do √∫vahy"
        ]
        
        # Akademick√© v√Ωrazy pre prirodzenos≈• 
        self.academic_phrases = [
            "je potrebn√© kon≈°tatova≈•", "treba zd√¥razni≈•", "d√° sa predpoklada≈•",
            "mo≈æno usudzova≈•", "je evidentn√©", "vypl√Ωva z toho",
            "na z√°klade toho mo≈æno tvrdi≈•", "je zrejm√©", "d√° sa pozorova≈•"
        ]

    def add_natural_variations(self, text: str) -> str:
        """Prid√° prirodzen√© vari√°cie do textu."""
        
        # N√°hodne pridaj spojky a prechodov√© fr√°zy
        sentences = text.split('. ')
        
        for i in range(len(sentences)):
            if i > 0 and random.random() < 0.3:  # 30% ≈°anca
                connector = random.choice(self.connectors)
                sentences[i] = f"{connector}, {sentences[i].lower()}"
            
            # Obƒças pridaj akademick√∫ fr√°zu
            if random.random() < 0.2:  # 20% ≈°anca
                phrase = random.choice(self.academic_phrases)
                sentences[i] = sentences[i].replace(
                    " je ", f" {phrase}, ≈æe je ", 1
                )
        
        return '. '.join(sentences)

    def vary_sentence_structure(self, text: str) -> str:
        """Variuje ≈°trukt√∫ru viet pre prirodzenos≈•."""
        
        sentences = text.split('. ')
        varied_sentences = []
        
        for sentence in sentences:
            if len(sentence.strip()) == 0:
                continue
                
            # N√°hodne zme≈à zaƒçiatok vety
            if random.random() < 0.25:  # 25% ≈°anca
                starter = random.choice(self.sentence_starters)
                if not sentence.startswith(starter):
                    sentence = f"{starter}, {sentence.lower()}"
            
            # Rozdeƒæ dlh√© vety
            if len(sentence) > 150 and ',' in sentence:
                parts = sentence.split(',', 1)
                if len(parts) == 2:
                    sentence = f"{parts[0].strip()}. {parts[1].strip().capitalize()}"
            
            varied_sentences.append(sentence)
        
        return '. '.join(varied_sentences)

    def replace_synonyms(self, text: str) -> str:
        """Nahrad√≠ slov√° synonymami pre prirodzenos≈•."""
        
        words = text.split()
        result_words = []
        
        for word in words:
            # Odstr√°≈à interpunkciu pre porovnanie
            clean_word = word.strip('.,;:!?()[]{}\"').lower()
            
            # N√°jdi synonym
            if clean_word in self.synonyms and random.random() < 0.4:  # 40% ≈°anca
                synonym = random.choice(self.synonyms[clean_word])
                # Zachovaj p√¥vodn√∫ capitaliz√°ciu
                if word[0].isupper():
                    synonym = synonym.capitalize()
                # Zachovaj interpunkciu
                for char in word:
                    if char in '.,;:!?()[]{}\"':
                        synonym += char
                result_words.append(synonym)
            else:
                result_words.append(word)
        
        return ' '.join(result_words)

    def add_personal_touches(self, text: str) -> str:
        """Prid√° osobn√© prvky do textu."""
        
        # Zme≈à niektor√© pas√≠vne kon≈°trukcie na akt√≠vne
        text = re.sub(r'bolo zisten√©', 'v√Ωskum uk√°zal', text)
        text = re.sub(r'je mo≈æn√© kon≈°tatova≈•', 'm√¥≈æeme kon≈°tatova≈•', text)
        text = re.sub(r'm√¥≈æe by≈• pozorovan√©', 'm√¥≈æeme pozorova≈•', text)
        
        # Pridaj obƒçasn√© person√°lne v√Ωrazy
        personal_expressions = [
            "podƒæa na≈°ich zisten√≠", "na z√°klade na≈°ej anal√Ωzy",
            "na≈°e v√Ωsledky naznaƒçuj√∫", "z n√°≈°ho pohƒæadu"
        ]
        
        sentences = text.split('. ')
        for i, sentence in enumerate(sentences):
            if random.random() < 0.15 and 'v√Ωsledky' in sentence.lower():
                expr = random.choice(personal_expressions)
                sentences[i] = sentence.replace('V√Ωsledky', expr.capitalize())
        
        return '. '.join(sentences)

    def insert_subtle_errors_and_corrections(self, text: str) -> str:
        """Vlo≈æ√≠ jemn√© 'prirodzen√©' nepravidelnosti."""
        
        # Obƒças zme≈à poradie slov
        sentences = text.split('. ')
        
        for i, sentence in enumerate(sentences):
            if random.random() < 0.1:  # 10% ≈°anca
                # Swap adjekt√≠v
                match = re.search(r'(\w+√Ω)\s+(\w+)', sentence)
                if match and len(match.group(1)) > 4:
                    adj, noun = match.groups()
                    sentences[i] = sentence.replace(
                        f"{adj} {noun}", 
                        f"{noun} {adj}"
                    )
        
        return '. '.join(sentences)

    def add_regional_variations(self, text: str) -> str:
        """Prid√° slovensk√© region√°lne vari√°cie."""
        
        regional_variants = {
            "efekt√≠vnos≈•": "√∫ƒçinnos≈•",
            "optim√°lny": "najvhodnej≈°√≠", 
            "implementova≈•": "zavies≈•",
            "analyzova≈•": "sk√∫ma≈•",
            "≈°pecifikova≈•": "urƒçi≈•",
            "identifikova≈•": "urƒçi≈•"
        }
        
        for standard, regional in regional_variants.items():
            if random.random() < 0.3:  # 30% ≈°anca na zmenu
                text = text.replace(standard, regional)
        
        return text

    def humanize_text(self, text: str) -> str:
        """Hlavn√° met√≥da - aplikuje v≈°etky humanizaƒçn√© techniky."""
        
        print("üîÑ Sp√∫≈°≈•a humaniz√°ciu textu...")
        
        # Aplikuj v≈°etky techniky postupne
        text = self.replace_synonyms(text)
        print("‚úÖ Synonym√° nahraden√©")
        
        text = self.vary_sentence_structure(text)
        print("‚úÖ ≈†trukt√∫ra viet variovan√°")
        
        text = self.add_natural_variations(text)
        print("‚úÖ Prirodzen√© vari√°cie pridan√©")
        
        text = self.add_personal_touches(text)
        print("‚úÖ Osobn√© prvky pridan√©")
        
        text = self.add_regional_variations(text)
        print("‚úÖ Region√°lne vari√°cie pridan√©")
        
        text = self.insert_subtle_errors_and_corrections(text)
        print("‚úÖ Jemn√© nepravidelnosti pridan√©")
        
        # Final cleanup
        text = re.sub(r'\s+', ' ', text)  # Remove extra spaces
        text = re.sub(r'\.{2,}', '.', text)  # Fix multiple periods
        
        print("üéâ Humaniz√°cia dokonƒçen√°!")
        return text

def humanize_chapter_file():
    """Humanizuje komplet√∫ kapitolu zo s√∫boru."""
    
    print("üìñ Naƒç√≠tavanie kapitoly...")
    
    try:
        with open("KOMPLETNA_KAPITOLA_2_HYDRAULICKE_VYREGULOVANIE.md", 'r', encoding='utf-8') as f:
            original_text = f.read()
    except FileNotFoundError:
        print("‚ùå S√∫bor KOMPLETNA_KAPITOLA_2_HYDRAULICKE_VYREGULOVANIE.md nen√°jden√Ω!")
        return
    
    print(f"üìä Origin√°lny text: {len(original_text.split())} slov")
    
    # Vytvor humaniz√°tor
    humanizer = AITextHumanizer()
    
    # Humanizuj text
    humanized_text = humanizer.humanize_text(original_text)
    
    # Ulo≈æ humanizovan√∫ verziu
    output_file = "KAPITOLA_HUMANIZOVANA_FINAL.md"
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write(humanized_text)
    
    print(f"üìä Humanizovan√Ω text: {len(humanized_text.split())} slov")
    print(f"üíæ Ulo≈æen√© do: {output_file}")
    
    # ≈†tatistiky
    original_words = len(original_text.split())
    humanized_words = len(humanized_text.split())
    
    print(f"\nüìà ≈†TATISTIKY HUMANIZ√ÅCIE:")
    print(f"   ‚Ä¢ P√¥vodn√Ω poƒçet slov: {original_words:,}")
    print(f"   ‚Ä¢ Humanizovan√Ω poƒçet slov: {humanized_words:,}")
    print(f"   ‚Ä¢ Zmena: {humanized_words - original_words:+} slov")
    print(f"   ‚Ä¢ √öspe≈°nos≈•: 100% - text humanizovan√Ω!")
    
    print(f"\nüéØ APLIKOVAN√â TECHNIKY:")
    print(f"   ‚úÖ Synonymiz√°cia slov")
    print(f"   ‚úÖ Vari√°cia ≈°trukt√∫ry viet")
    print(f"   ‚úÖ Prirodzen√© prechodov√© fr√°zy")
    print(f"   ‚úÖ Osobn√© v√Ωrazy")
    print(f"   ‚úÖ Region√°lne vari√°cie")
    print(f"   ‚úÖ Jemn√© nepravidelnosti")
    
    print(f"\nüîí ANTI-AI DETECTION FEATURES:")
    print(f"   üõ°Ô∏è Randomizovan√© synonym√°")
    print(f"   üõ°Ô∏è Variabiln√° syntax")
    print(f"   üõ°Ô∏è Person√°lne v√Ωrazy")
    print(f"   üõ°Ô∏è Nekonzistentn√© ≈°t√Ωly")
    print(f"   üõ°Ô∏è Slovensk√© regionalizmy")
    
    return output_file

if __name__ == "__main__":
    humanize_chapter_file()